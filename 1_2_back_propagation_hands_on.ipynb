{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "1_2_back_propagation_hands_on.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanri3/deep_learning_day1_day2/blob/main/1_2_back_propagation_hands_on.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5L0AWliZYng"
      },
      "source": [
        "# importと関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNcuxoGogLvM"
      },
      "source": [
        "import numpy as np\n",
        "# from common import functions\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "def print_vec(text, vec):\n",
        "    print(\"*** \" + text + \" ***\")\n",
        "    np.set_printoptions(precision=5)\n",
        "    print(vec)\n",
        "    print(\"shape:\", vec.shape)\n",
        "    #print(\"shape: \" + str(x.shape))\n",
        "    # print(\"\")\n",
        "\n",
        "\n",
        "# ReLU関数\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "# 中間層の活性化関数\n",
        "# シグモイド関数（ロジスティック関数）\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "# 出力層の活性化関数\n",
        "# ソフトマックス関数\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T\n",
        "    x = x - np.max(x) # オーバーフロー対策\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "# クロスエントロピー\n",
        "def cross_entropy_error(d, y):\n",
        "    if y.ndim == 1:\n",
        "        d = d.reshape(1, d.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
        "    # One-hotベクトルとは、(0,1,0,0,0,0) の様に、1つの成分が1で残りの成分が全て0であるベクトルのこと\n",
        "    if d.size == y.size:\n",
        "        # NumPyのargmax関数は、多次元配列の中の最大値の要素を持つインデックスを返す関数\n",
        "        d = d.argmax(axis=1)\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), d] + 1e-7)) / batch_size\n",
        "# 誤差関数\n",
        "# 平均二乗誤差\n",
        "def mean_squared_error(d, y):\n",
        "    return np.mean(np.square(d - y)) / 2\n",
        "# シグモイドとクロスエントロピーの複合導関数\n",
        "def d_sigmoid_with_loss(d, y):\n",
        "    return y - d\n",
        "# ReLU関数の導関数\n",
        "def d_relu(x):\n",
        "    return np.where( x > 0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhkhpJjOgbtF"
      },
      "source": [
        "# メインプログラム"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma1nAxuegLvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c178c3-c361-46f0-fd1a-fb0573376c9d"
      },
      "source": [
        "# ウェイトとバイアスを設定\n",
        "# ネートワークを作成\n",
        "def init_network():\n",
        "    print(\"##### ネットワークの初期化 #####\")\n",
        "    network = {}\n",
        "    network['W1'] = np.array([\n",
        "        [0.1, 0.3, 0.5],\n",
        "        [0.2, 0.4, 0.6]\n",
        "    ])\n",
        "    network['W2'] = np.array([\n",
        "        [0.1, 0.4],\n",
        "        [0.2, 0.5],\n",
        "        [0.3, 0.6]\n",
        "    ])\n",
        "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
        "    network['b2'] = np.array([0.1, 0.2])\n",
        "    print_vec(\"重み1\", network['W1'])\n",
        "    print_vec(\"重み2\", network['W2'])\n",
        "    print_vec(\"バイアス1\", network['b1'])\n",
        "    print_vec(\"バイアス2\", network['b2'])\n",
        "\n",
        "    return network\n",
        "\n",
        "# 順伝播\n",
        "def forward(network, x):\n",
        "    print(\"##### 順伝播開始 #####\")\n",
        "    W1, W2 = network['W1'], network['W2']\n",
        "    b1, b2 = network['b1'], network['b2']\n",
        "    \n",
        "    u1 = x @ W1 + b1\n",
        "    # u1 = np.dot(x, W1) + b1\n",
        "    z1 = relu(u1)\n",
        "    # z1 = functions.relu(u1)\n",
        "    u2 = z1 @ W2 + b2\n",
        "    # u2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(u2)\n",
        "    # y = functions.softmax(u2)\n",
        "    \n",
        "    print_vec(\"総入力1\", u1)\n",
        "    print_vec(\"中間層出力1\", z1)\n",
        "    print_vec(\"総入力2\", u2)\n",
        "    print_vec(\"出力1\", y)\n",
        "    print(\"出力合計: \" + str(np.sum(y)))\n",
        "    return y, z1\n",
        "\n",
        "# 誤差逆伝播\n",
        "def backward(x, d, z1, y):\n",
        "    print(\"\\n##### 誤差逆伝播開始 #####\")\n",
        "    grad = {}\n",
        "    W1, W2 = network['W1'], network['W2']\n",
        "    b1, b2 = network['b1'], network['b2']\n",
        "    #  出力層でのデルタ\n",
        "    delta2 = y - d\n",
        "    # delta2 = d_sigmoid_with_loss(d, y)\n",
        "    # delta2 = functions.d_sigmoid_with_loss(d, y)\n",
        "    #  b2の勾配\n",
        "    grad['b2'] = np.sum(delta2, axis=0)\n",
        "    #  W2の勾配\n",
        "    grad['W2'] = z1.T @ delta2\n",
        "    # grad['W2'] = np.dot(z1.T, delta2)\n",
        "    #  中間層でのデルタ\n",
        "    delta1 = (delta2 @ W2.T) * d_relu(z1)\n",
        "    # delta1 = np.dot(delta2, W2.T) * functions.d_relu(z1)\n",
        "    # b1の勾配\n",
        "    grad['b1'] = np.sum(delta1, axis=0)\n",
        "    #  W1の勾配\n",
        "    grad['W1'] = x.T @ delta1\n",
        "    # grad['W1'] = np.dot(x.T, delta1)\n",
        "        \n",
        "    print_vec(\"偏微分_dE/du2\", delta2)\n",
        "    print_vec(\"偏微分_dE/du2\", delta1)\n",
        "    print_vec(\"偏微分_重み1\", grad[\"W1\"])\n",
        "    print_vec(\"偏微分_重み2\", grad[\"W2\"])\n",
        "    print_vec(\"偏微分_バイアス1\", grad[\"b1\"])\n",
        "    print_vec(\"偏微分_バイアス2\", grad[\"b2\"])\n",
        "    return grad\n",
        "    \n",
        "# 訓練データ\n",
        "x = np.array([[1.0, 5.0]])\n",
        "# 目標出力\n",
        "d = np.array([[0, 1]])\n",
        "#  学習率\n",
        "learning_rate = 0.01\n",
        "network =  init_network()\n",
        "y, z1 = forward(network, x)\n",
        "\n",
        "# 誤差\n",
        "# loss = cross_entropy_error(d, y)\n",
        "# loss = functions.cross_entropy_error(d, y)\n",
        "\n",
        "grad = backward(x, d, z1, y)\n",
        "num=0\n",
        "for key in ('W1', 'W2', 'b1', 'b2'):\n",
        "    network[key]  -= learning_rate * grad[key]\n",
        "    print(\"num:\", num)\n",
        "    num+=1\n",
        "\n",
        "print(\"##### 結果表示 #####\")    \n",
        "print(\"##### 更新後パラメータ #####\") \n",
        "print_vec(\"重み1\", network['W1'])\n",
        "print_vec(\"重み2\", network['W2'])\n",
        "print_vec(\"バイアス1\", network['b1'])\n",
        "print_vec(\"バイアス2\", network['b2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### ネットワークの初期化 #####\n",
            "*** 重み1 ***\n",
            "[[0.1 0.3 0.5]\n",
            " [0.2 0.4 0.6]]\n",
            "shape: (2, 3)\n",
            "*** 重み2 ***\n",
            "[[0.1 0.4]\n",
            " [0.2 0.5]\n",
            " [0.3 0.6]]\n",
            "shape: (3, 2)\n",
            "*** バイアス1 ***\n",
            "[0.1 0.2 0.3]\n",
            "shape: (3,)\n",
            "*** バイアス2 ***\n",
            "[0.1 0.2]\n",
            "shape: (2,)\n",
            "##### 順伝播開始 #####\n",
            "*** 総入力1 ***\n",
            "[[1.2 2.5 3.8]]\n",
            "shape: (1, 3)\n",
            "*** 中間層出力1 ***\n",
            "[[1.2 2.5 3.8]]\n",
            "shape: (1, 3)\n",
            "*** 総入力2 ***\n",
            "[[1.86 4.21]]\n",
            "shape: (1, 2)\n",
            "*** 出力1 ***\n",
            "[[0.08707 0.91293]]\n",
            "shape: (1, 2)\n",
            "出力合計: 1.0\n",
            "\n",
            "##### 誤差逆伝播開始 #####\n",
            "*** 偏微分_dE/du2 ***\n",
            "[[ 0.08707 -0.08707]]\n",
            "shape: (1, 2)\n",
            "*** 偏微分_dE/du2 ***\n",
            "[[-0.02612 -0.02612 -0.02612]]\n",
            "shape: (1, 3)\n",
            "*** 偏微分_重み1 ***\n",
            "[[-0.02612 -0.02612 -0.02612]\n",
            " [-0.1306  -0.1306  -0.1306 ]]\n",
            "shape: (2, 3)\n",
            "*** 偏微分_重み2 ***\n",
            "[[ 0.10448 -0.10448]\n",
            " [ 0.21766 -0.21766]\n",
            " [ 0.33085 -0.33085]]\n",
            "shape: (3, 2)\n",
            "*** 偏微分_バイアス1 ***\n",
            "[-0.02612 -0.02612 -0.02612]\n",
            "shape: (3,)\n",
            "*** 偏微分_バイアス2 ***\n",
            "[ 0.08707 -0.08707]\n",
            "shape: (2,)\n",
            "num: 0\n",
            "num: 1\n",
            "num: 2\n",
            "num: 3\n",
            "##### 結果表示 #####\n",
            "##### 更新後パラメータ #####\n",
            "*** 重み1 ***\n",
            "[[0.10026 0.30026 0.50026]\n",
            " [0.20131 0.40131 0.60131]]\n",
            "shape: (2, 3)\n",
            "*** 重み2 ***\n",
            "[[0.09896 0.40104]\n",
            " [0.19782 0.50218]\n",
            " [0.29669 0.60331]]\n",
            "shape: (3, 2)\n",
            "*** バイアス1 ***\n",
            "[0.10026 0.20026 0.30026]\n",
            "shape: (3,)\n",
            "*** バイアス2 ***\n",
            "[0.09913 0.20087]\n",
            "shape: (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}